version: '3.8'
services:
  alfa-wall-addon:
    build: ../Alfa1-wall-addon
    environment:
      # LLM Configuration - All can be overridden via environment variables
      # Get your OpenRouter API key at: https://openrouter.ai/keys
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - SPRING_AI_OPENAI_BASE_URL=${SPRING_AI_OPENAI_BASE_URL:-https://openrouter.ai/api/v1}
      - SPRING_AI_OPENAI_CHAT_OPTIONS_MODEL=${SPRING_AI_OPENAI_CHAT_OPTIONS_MODEL:-openai/gpt-4o-mini}
      - SPRING_AI_OPENAI_CHAT_OPTIONS_TEMPERATURE=${SPRING_AI_OPENAI_CHAT_OPTIONS_TEMPERATURE:-0.7}
      - EMBABEL_MODELS_DEFAULT_LLM=${EMBABEL_MODELS_DEFAULT_LLM:-gpt-4.1-mini}
      # Home Assistant Configuration
      - HOME_ASSISTANT_LONG_LIVED_ACCES_TOKEN=${HOME_ASSISTANT_LONG_LIVED_ACCES_TOKEN}
    ports:
      - "8080:8080"

  home-assistant:
    build: ./home-assistant/docker
    profiles:
      - local-testing
    volumes:
      - ./home-assistant/config:/config
    ports:
      - "8123:8123"

  wled-simulator:
    build: ./wled-simulator
    profiles:
      - local-testing
    environment:
      - SERVER_PORT=80
    ports:
      - "8081:80"
